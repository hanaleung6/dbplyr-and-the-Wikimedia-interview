---
title: "dbplyr and the Wikimedia interview"
author: "Yongqi Liang"
date: "12 August 2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Task description and data for candidates applying to be a Data Analyst in the [Discovery department](https://www.mediawiki.org/wiki/Wikimedia_Discovery) at [Wikimedia Foundation](https://wikimediafoundation.org/wiki/Home).

## Background

Discovery (and other teams within the Foundation) rely on *event logging* (EL) to track a variety of performance and usage metrics to help us make decisions. Specifically, Discovery is interested in:

- *clickthrough rate*: the proportion of search sessions where the user clicked on one of the results displayed
- *zero results rate*: the proportion of searches that yielded 0 results

and other metrics outside the scope of this task. EL uses JavaScript to asynchronously send messages (events) to our servers when the user has performed specific actions. In this task, you will analyze a subset of our event logs.


## Data

The required data set, `events_log.csv` comes from a [tracking schema](https://meta.wikimedia.org/wiki/Schema:TestSearchSatisfaction2) that we use for assessing user satisfaction. Desktop users are randomly sampled to be anonymously tracked by this schema which uses a "I'm alive" pinging system that we can use to estimate how long our users stay on the pages they visit. The dataset contains just a little more than a week of EL data.

| Column          | Value   | Description                                                                       |
|:----------------|:--------|:----------------------------------------------------------------------------------|
| uuid            | string  | Universally unique identifier (UUID) for backend event handling.                  |
| timestamp       | integer | The date and time (UTC) of the event, formatted as YYYYMMDDhhmmss.                |
| session_id      | string  | A unique ID identifying individual sessions.                                      |
| group           | string  | A label ("a" or "b").                                     |
| action          | string  | Identifies in which the event was created. See below.                             |
| checkin         | integer | How many seconds the page has been open for.                                      |
| page_id         | string  | A unique identifier for correlating page visits and check-ins.                    |
| n_results       | integer | Number of hits returned to the user. Only shown for searchResultPage events.      |
| result_position | integer | The position of the visited page's link on the search engine results page (SERP). |

The following are possible values for an event's action field:

- **searchResultPage**: when a new search is performed and the user is shown a SERP.
- **visitPage**: when the user clicks a link in the results.
- **checkin**: when the user has remained on the page for a pre-specified amount of time.

### Example Session

|uuid                             |      timestamp|session_id       |group |action           | checkin|page_id          | n_results| result_position|
|:--------------------------------|:--------------|:----------------|:-----|:----------------|-------:|:----------------|---------:|---------------:|
|4f699f344515554a9371fe4ecb5b9ebc | 20160305195246|001e61b5477f5efc |b     |searchResultPage |      NA|1b341d0ab80eb77e |         7|              NA|
|759d1dc9966353c2a36846a61125f286 | 20160305195302|001e61b5477f5efc |b     |visitPage        |      NA|5a6a1f75124cbf03 |        NA|               1|
|77efd5a00a5053c4a713fbe5a48dbac4 | 20160305195312|001e61b5477f5efc |b     |checkin          |      10|5a6a1f75124cbf03 |        NA|               1|
|42420284ad895ec4bcb1f000b949dd5e | 20160305195322|001e61b5477f5efc |b     |checkin          |      20|5a6a1f75124cbf03 |        NA|               1|
|8ffd82c27a355a56882b5860993bd308 | 20160305195332|001e61b5477f5efc |b     |checkin          |      30|5a6a1f75124cbf03 |        NA|               1|
|2988d11968b25b29add3a851bec2fe02 | 20160305195342|001e61b5477f5efc |b     |checkin          |      40|5a6a1f75124cbf03 |        NA|               1|

This user's search query returned 7 results, they clicked on the first result, and stayed on the page between 40 and 50 seconds. (The next check-in would have happened at 50s.) Since this session has a "visitPage" action, it has clicked-through.

## Reading the data

`data` is the name of an empty folder that I want to put the database in 
```{r}
library(RSQLite)
library(DBI)
sqcon<- dbConnect(dbDriver("SQLite"), "data/sqlite.db")
events <- read_csv("events_log.csv")
sqevents <- copy_to(sqcon, events, temporary = FALSE, overwrite = TRUE)
```

The object `sqevents` is the dbplyr "lazy" data frame 

If something goes wrong you will need to shutdown the database server
```
DBI::dbDisconnect(sqcon, shutdown=TRUE)
```

## Main task 

1. What is the overall clickthrough rate? 

2. What is the clickthrough rate by day?

3. What is the clickthrough rate by group?

When you are done, shut down the database server
```{r}
# The overall clickthrough rate
sqevents %>% 
  group_by(session_id) %>% 
  summarise(countofvisit = sum(action == "visitPage")) %>%
  summarise(mean(countofvisit>0)) %>% 
  collect()
```
Hence, the overall clickthrough rate is **0.389**.

```{r}
# The clickthrough rate by day
sqevents %>% 
  mutate(year = substr(as.character(timestamp), 1, 4), 
         month = substr(as.character(timestamp), 5, 6), 
         day = substr(as.character(timestamp), 7, 8)) %>% 
  group_by(day, session_id) %>% 
  summarise(countofvisit = sum(action == "visitPage")) %>%
  summarise(mean(countofvisit>0)) %>% 
  collect()
```

```{r}
# The clickthrough rate by group
sqevents %>% 
  group_by(session_id, group) %>% 
  summarise(countofvisit=sum(action=="visitPage")) %>% 
  group_by(group) %>%
  summarise(mean(countofvisit>0)) %>%
  arrange(group) %>%
  collect()
```

```{r}
dbDisconnect(sqcon, shutdown=TRUE)
```

## Timings

Compare the speed of in-memory and SQLite versions of the code as if you were starting off with the data in a database. Use `system.time()` to help with this task.

First direct in the database
```{r}
# get DB connection 
sqcon<- dbConnect(dbDriver("SQLite"), "data/sqlite.db")
sqevents <- tbl(sqcon,"events")
# time it
sqtime <- system.time(sqevents %>% 
  mutate(year = substr(as.character(timestamp), 1, 4), 
         month = substr(as.character(timestamp), 5, 6), 
         day = substr(as.character(timestamp), 7, 8)) %>% 
  group_by(day, session_id) %>% 
  summarise(countofvisit = sum(action == "visitPage")) %>%
  summarise(mean(countofvisit>0)) %>% 
    collect())
sqtime
```

Now time for in-memory by reading it in from database then doing calculation locally.
```{r}
# time the reading in 
system.time(sqevents %>% collect())
```

```{r}
# time the calculation
localtime <- system.time(events %>% 
  mutate(year = substr(as.character(timestamp), 1, 4), 
         month = substr(as.character(timestamp), 5, 6), 
         day = substr(as.character(timestamp), 7, 8)) %>% 
  group_by(day, session_id) %>% 
  summarise(countofvisit = sum(action == "visitPage")) %>%
  summarise(mean(countofvisit>0)))
localtime
```
Much faster for this task in the database rather than in memory, even not taking into account the time to read it in.
